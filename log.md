* rawpixelsbackgoundsv3 - I can get .2629 loss with just background and 3 epochs, with 1 epoch I got around .4, I wonder if I increase epochs to 8 will it increase more. next I want to introduce 1 shape with a background color, I will try that next
* rawpixelsbackgoundsv4 - will loss continue to go down?

experiment: resnetvsrawpixelbackgroundsv1 | started training at: Thu Jun 22 12:39:21 2017 | params: {"model_path": "./models/", "name": "resnetvsrawpixelbackgroundsv1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/256kbackgrounds/", "log_step": 10, "save_step": 1000, "embed_size": 2700, "hidden_size": 600, "num_layers": 2, "notes": "backgrounds with pixels is low loss, i want to see if the cnn is better", "loss": null, "num_epochs": 3, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_vs_pixels_backgrounds_shapes_v1 | started training at: Thu Jun 22 12:44:49 2017 | params: {"model_path": "./models/", "name": "cnn_vs_pixels_backgrounds_shapes_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/356kbackgrounds_1shape/", "log_step": 10, "save_step": 1000, "embed_size": 2700, "hidden_size": 600, "num_layers": 2, "notes": "comparing loss on pixels vs cnn in another test ", "loss": null, "num_epochs": 5, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_vs_pixels_backgrounds_shapes_v2 | started training at: Thu Jun 22 16:20:08 2017 | params: {"model_path": "./models/", "name": "cnn_vs_pixels_backgrounds_shapes_v2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/356kbackgrounds_1shape/", "log_step": 10, "save_step": 1000, "embed_size": 2700, "hidden_size": 600, "num_layers": 2, "notes": "comparing loss on pixels vs cnn in another test,increased epochs ", "loss": null, "num_epochs": 15, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: moredata4regionshapesv1 | started training at: Thu Jun 22 16:32:27 2017 | params: {"model_path": "./models/", "name": "moredata4regionshapesv1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/700k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 600, "num_layers": 2, "notes": "first time trying data over 100k ,this is 700k,see if it actually helps", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: train_resnet_v1 | started training at: Thu Jun 22 18:32:35 2017 | params: {"model_path": "./models/", "name": "train_resnet_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/256kbackgrounds/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 600, "num_layers": 2, "notes": "first time trying without pretrained cnn", "loss": null, "num_epochs": 1, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: train_resnet_v2 | started training at: Thu Jun 22 19:07:07 2017 | params: {"model_path": "./models/", "name": "train_resnet_v2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/256kbackgrounds/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 600, "num_layers": 2, "notes": "2nd time trying withou\nt pretrained cnn", "loss": null, "num_epochs": 10, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: moredata4regionshapesv1 | started training at: Thu Jun 22 22:37:29 2017 | params: {"model_path": "./models/", "name": "moredata4regionshapesv1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/700k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 600, "num_layers": 2, "notes": "first time trying data over 100k ,this is 700k,see if it actually helps", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: train_resnet_v3 | started training at: Fri Jun 23 06:38:37 2017 | params: {"model_path": "./models/", "name": "train_resnet_v3", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/256kbackgrounds/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "hidden equel embed size and 3 layers", "loss": null, "num_epochs": 1, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: larger_rnn_pretrained_resnset | started training at: Fri Jun 23 07:01:28 2017 | params: {"model_path": "./models/", "name": "larger_rnn_pretrained_resnset", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/256kbackgrounds/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "hidden equel embed size and 3 layers on pretrained resnet", "loss": null, "num_epochs": 1, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v1 | started training at: Fri Jun 23 07:35:20 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/100k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 1, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v1 | started training at: Fri Jun 23 07:37:18 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/100k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 1, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v1 | started training at: Fri Jun 23 07:39:34 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/100k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 1, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v1 | started training at: Fri Jun 23 07:42:48 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/100k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 1, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v1 | started training at: Fri Jun 23 07:43:45 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/100k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 1, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v1 | started training at: Fri Jun 23 08:43:50 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/100k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 3, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v1 | started training at: Fri Jun 23 08:44:38 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/100k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 3, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v1 | started training at: Fri Jun 23 08:46:46 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/100k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 3, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v2 | started training at: Fri Jun 23 08:47:05 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/256kbackgrounds/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v1 | started training at: Fri Jun 23 10:32:19 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/100k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 3, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 3, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: cnn_plus_pixels_backgrounds_1_image_v1 | started training at: Fri Jun 23 10:34:47 2017 | params: {"model_path": "./models/", "name": "cnn_plus_pixels_backgrounds_1_image_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/100k_4scaleregions_r256/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 2048, "num_layers": 2, "notes": "testing if I can combine pixels with resnet pretrained", "loss": null, "num_epochs": 3, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evg_david_v1 | started training at: Fri Jun 23 19:25:58 2017 | params: {"model_path": "./models/", "name": "evg_david_v1", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 2048, "hidden_size": 600, "num_layers": 2, "notes": "2nd time trying withou\nt pretrained cnn", "loss": null, "num_epochs": 10, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evg_david_v2 | started training at: Mon Jun 26 08:49:29 2017 | params: {"model_path": "./models/", "name": "evg_david_v2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "model broke,retraining", "loss": null, "num_epochs": 5, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evg_david_v2 | started training at: Mon Jun 26 08:50:09 2017 | params: {"model_path": "./models/", "name": "evg_david_v2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "model broke,retraining", "loss": null, "num_epochs": 5, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evg_david_v2 | started training at: Mon Jun 26 08:51:21 2017 | params: {"model_path": "./models/", "name": "evg_david_v2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "model code broke,retraining, similiar to v1", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evg_david_v3 | started training at: Mon Jun 26 13:37:02 2017 | params: {"model_path": "./models/", "name": "evg_david_v3", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "model code broke,retraining, similiar to v1", "loss": null, "num_epochs": 5, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evg_david_v4 | started training at: Mon Jun 26 14:59:25 2017 | params: {"model_path": "./models/", "name": "evg_david_v4", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 2, "notes": "go back to original code since everything is breaking", "loss": null, "num_epochs": 5, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evg_david_v5 | started training at: Tue Jun 27 06:58:17 2017 | params: {"model_path": "./models/", "name": "evg_david_v5", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 2, "notes": "go back to original code since everything is breaking", "loss": null, "num_epochs": 1, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evg_david_v5 | started training at: Tue Jun 27 07:31:20 2017 | params: {"model_path": "./models/", "name": "evg_david_v5", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "fixed,data loader broken, just training now", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evg_david_v6 | started training at: Tue Jul  4 14:40:51 2017 | params: {"model_path": "./models/", "name": "evg_david_v6", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 2, "notes": "go back to original code since everything is breaking", "loss": null, "num_epochs": 5, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evg_david_v7 | started training at: Thu Jul  6 13:02:13 2017 | params: {"model_path": "./models/", "name": "evg_david_v7", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 2, "notes": "use our own resnet", "loss": null, "num_epochs": 5, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: test_upgrades | started training at: Thu Jul  6 13:21:07 2017 | params: {"model_path": "./models/", "name": "test_upgrades", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "see if cuda still works", "loss": null, "num_epochs": 1, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: test_upgrades2 | started training at: Thu Jul  6 13:28:28 2017 | params: {"model_path": "./models/", "name": "test_upgrades2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_84k_r256_v1/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "see if cuda still works", "loss": null, "num_epochs": 5, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001}
experiment: evgdatasetv2 | started training at: Thu Jul  6 15:16:31 2017 | params: {"model_path": "./models/", "name": "evgdatasetv2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_170k_r256_v2/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "what happens if we double the size", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": null}
experiment: evgdatasetv3 | started training at: Thu Jul  6 18:10:07 2017 | params: {"model_path": "./models/", "name": "evgdatasetv3", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_34k_r256_v3/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "what happens if we add objects inside", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": null}
experiment: evgdatasetv4 | started training at: Thu Jul  6 22:25:08 2017 | params: {"model_path": "./models/", "name": "evgdatasetv4", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_500k_v4/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "objects inside plus second object", "loss": null, "num_epochs": 3, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": null}
experiment: evgdatasetv4paramvsv2 | started training at: Fri Jul  7 07:35:17 2017 | params: {"model_path": "./models/", "name": "evgdatasetv4paramvsv2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_500k_v4/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 2, "notes": "objects inside plus second object", "loss": null, "num_epochs": 3, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": null}
experiment: evgdatasetv3v2 | started training at: Fri Jul  7 10:59:27 2017 | params: {"model_path": "./models/", "name": "evgdatasetv3v2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_34k_r256_v3/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 2, "notes": "what happens if we add objects inside and increase layers", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": null}
experiment: evg_david_67k_2shapes | started training at: Fri Jul  7 16:12:22 2017 | params: {"model_path": "./models/", "name": "evg_david_67k_2shapes", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_67k_2shapes/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 1, "notes": "try with 2 items in evg", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": null}
experiment: evg_david_67k_2shapesv2 | started training at: Fri Jul  7 16:38:45 2017 | params: {"model_path": "./models/", "name": "evg_david_67k_2shapesv2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_67k_2shapes/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 3, "notes": "try with 2 items in evg", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": "localhost"}
experiment: evg5shapes100k | started training at: Fri Jul  7 16:51:06 2017 | params: {"model_path": "./models/", "name": "evg5shapes100k", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_100k_5shapes/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 2, "notes": "5 objects now", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": "localhost"}
experiment: evg10shapes200k | started training at: Fri Jul  7 19:07:18 2017 | params: {"model_path": "./models/", "name": "evg10shapes200k", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_10shapes_200k/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 2, "notes": "10 objects now", "loss": null, "num_epochs": 3, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": "localhost"}
experiment: evg_david_800k_2shapesv3 | started training at: Fri Jul  7 19:58:11 2017 | params: {"model_path": "./models/", "name": "evg_david_800k_2shapesv3", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_david_v7_800k/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 3, "notes": "try with 2 items in evg", "loss": null, "num_epochs": 2, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": "localhost"}
experiment: evg10shapes200kv2 | started training at: Sat Jul  8 11:14:37 2017 | params: {"model_path": "./models/", "name": "evg10shapes200kv2", "crop_size": 224, "vocab_path": null, "image_dir": "/home/jtoy/sandbox/datasets/evg_10shapes_200k/", "log_step": 10, "save_step": 1000, "embed_size": 256, "hidden_size": 512, "num_layers": 2, "notes": "10 objects now more epochs", "loss": null, "num_epochs": 5, "batch_size": 128, "num_workers": 2, "learning_rate": 0.001, "tensorboard": "localhost"}
